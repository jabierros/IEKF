
clear all
close all
seed=1789
rng(seed) %every run random numbers are repeated
ode45_options=odeset('RelTol',1e-12); %,'AbsTol',1e-12)

% Segway Gyro and Accel

%% Parameter and initial state definition
R=0.25
delta1=0.0
delta3=1
m_R=15
m_P=80
I_R=1/2*(0.5*m_R)*R^2
I_P=m_P*(delta1^2+delta3^2)/(4)^2
c=(m_R+m_P)*0.75/2 %Delta_s=v*t+1/2*a*t^2=2m=2m/s*4s+1/2*a*(4s)^2 => a=(2-8)/(8)=0.75
k_c=1.5*800;
c_c=100
g=9.8;
theta0=0;
dtheta0=0;
Delta_t=0.001;

fig_dir=['Information_EKF_',num2str(Delta_t)];
mkdir(fig_dir);

param=[R delta1 delta3 m_R m_P I_R I_P c k_c c_c g Delta_t ]'

x=0
theta=0.01*pi/180
dx=0
dtheta=0

q=[x,theta]'
dq=[dx,dtheta]'

x_0_=[q;dq]
u_0_=[theta0]
du_0_=[dtheta0]
x_=x_0_
u_=u_0_
du_=du_0_
T=15

%% Generating input and noise to run and validate the filter

t_series=[0:Delta_t:T]

theta0_series=10*pi/180*(heaviside(t_series-5)-heaviside(t_series-10));

du_series=0*t_series

%Sensor white noise definition and generation
sigma_gyro=0.5; % rad/s
sigma_acc_x=0.1*10; % m/s^2
sigma_acc_z=0.1*10; % m/s^2

Sigma_z=diag([sigma_gyro,sigma_acc_x,sigma_acc_z])

n_z=size(Sigma_z,1)
z_series_noise=[];
for k=1:length(t_series)
    z_series_noise=[z_series_noise, Sigma_z*randn(n_z,1)];
end

%Input white noise definition and generation
sigma_theta0=0.1*10*pi/180; % rad <-- 3.6 deg

theta0_series_noise=[];
for k=1:length(t_series)
    theta0_series_noise=[theta0_series_noise, sigma_theta0*randn(1,1)];
end

%% Initial filter state

delta_x0=10 % m
delta_theta0=30*pi/180 % rad
delta_dx0=1 %  m/s
delta_dtheta0=1/(delta1^2+delta3^2)^0.5 %angular velocity if at  1m/s the wheel stops abruptly

%initial state expected value
mu_x_0_=x_0_+[delta_x0;
    delta_theta0;
    delta_dx0;
    delta_dtheta0];

mu_x_=mu_x_0_;

%initial state covariance
Sigma2_x_0_ = diag([delta_x0^2,delta_theta0^2,delta_dx0^2,delta_dtheta0^2])
Sigma2_x_ = Sigma2_x_0_;

%% Read input (k=1)
t=t_series(1,1);
u_=[theta0_series(:,1)+theta0_series_noise(:,1),mu_x_(2,1),mu_x_(4,1)]';
z_without_noise=h(x_,[theta0_series(:,1),x_(2,1),x_(4,1)]',t,param);
z_=z_without_noise+z_series_noise(:,1);

% Effect of noise in u on model covariance (f_u_ is dependent on the state)
f_u_=f_u(mu_x_,u_,t,param);
sigma_u_2=diag([sigma_theta0^2,Sigma2_x_(2,2),Sigma2_x_(4,4)]);
Q_u= f_u_*sigma_u_2*f_u_';

% Discretization error effect on model covariance
Q_discr= (diag([3.0e-5,3.0e-5,0.0015,0.0015]))^2;
% Discretization error and measured input error are assumed independent
Q=Q_discr+Q_u

h_u_=h_u(f(mu_x_,u_,t,param),u_,t+Delta_t,param)
% Effect of noise in u on sensor equation covariance
R_u= h_u_*sigma_u_2*h_u_'

R_z=diag([sigma_gyro^2,sigma_acc_x^2,sigma_acc_z^2])
% Sensor error and measured input error are assumed independent
R=R_z+R_u

x_series=[x_];
mu_x_series=[mu_x_];
z_series=[h(x_,u_,t,param)];
z_series_noisy=[z_];
sigma_x_=diag(Sigma2_x_).^0.5;
sigma_x_series=[sigma_x_];
pred_error_series=[zeros(size(x_))];

for k=1:T/Delta_t
     
    %%---Begin--- One step of Kalman filter (k-th)
    
    %% Prediction
    f_u_=f_u(mu_x_,u_,t,param);
    % effect of noise in u on model covariance (f_u_ is dependent on the state)
    Q_u= f_u_*sigma_u_2*f_u_';
    
    % Discretization error effect on model covariance
    Q_discr= (1/factorial(2)*diag([0.1*Delta_t^2,0.1*Delta_t^2,5*Delta_t^2,5*Delta_t^2]))^2
    % Q_discr= diag([1.52e-8,1.52e-8,2.01e-7,2.01e-7])^2;
    % Q_discr= (1/factorial(2)*diag(ddstate(x_est_,K*x_est_(2,1)+C*x_est_(4,1),du_series(1),t_series(1),param)'.*[Delta_t^2,Delta_t^2,Delta_t^2,Delta_t^2]))^2;

    % Discretization error and measured input error are assumed independent
    Q=Q_discr+Q_u;
    
    F_=F(mu_x_,u_,t,param);
    mu_x_pred_=f(mu_x_,u_,t,param);
    Sigma2_x_pred=F_*Sigma2_x_*F_'+Q;
    I_pred=inv(Sigma2_x_pred);
    
    %% Read Input and Sensor (k+1)
    
    %Read sensors k+1
    %z_=z_series(:,k+1)+z_series_noise(:,k+1);
    t_prev=t;
    
    %Sensor data is generated from true system estate (using h) and adding noise
    %True system state is generated by integration using MATLAB ode45 integrator 
    [time_steps,x_steps] = ode45(@(t,x_) dstate(x_, [theta0_series(:,k),mu_x_(2,1),mu_x_(4,1)]', t,param),[t_series(1,k),t_series(1,k+1)],x_,ode45_options);
    x_=x_steps(end,:)';
    z_without_noise=h(x_,[theta0_series(:,k+1),x_(2,1),x_(4,1)]', t_series(1,k+1),param);
    z_=z_without_noise+z_series_noise(:,k+1);
    pred_error=f(x_series(:,k),[theta0_series(:,k),mu_x_(2,1),mu_x_(4,1)]',t_series(1,k),param)-x_;
    %Exponential discretization A and B are continuous state Jacobian wrt 
    %x and u
    %x_ = eye(n_x) x_ + Delta_t * inv( A * Delta_t )*( expm( A * Delta_t ) - eye(n_x) )*f(u);
    %x_ = ( eye(n_x) + Delta_t * inv( A * Delta_t )*( expm( A * Delta_t ) -
    %eye(n_x) ) * A ) * x_ + Delta_t * inv( A * Delta_t )*( expm( A *
    %Delta_t ) * (A - f(x_,u_))
    
    %Read input k+1
    t=t_series(1,k+1);
    u_=[theta0_series(:,k)+theta0_series_noise(:,k+1),mu_x_pred_(2,1),mu_x_pred_(4,1)]';%There is not prediction for u we need to use previous stimate
    %or change philosophy
    
    %% Correction
    h_u_= h_u(mu_x_pred_,u_,t,param) ;
    % effect of noise in u on sensor equation covariance
    R_u= h_u_*sigma_u_2*h_u_';
    
    R_z=diag([sigma_gyro^2,sigma_acc_x^2,sigma_acc_z^2]);
    % Sensor error and measured input error are assumed independent
    R=R_z+R_u;
    
    H_= H(mu_x_pred_,u_,t,param);
    mu_x_corr_=+pinv(H_)*(z_-h(mu_x_pred_,u_,t,param)+H_*mu_x_pred_);
    Sigma2_x_corr=pinv(H_)*R*pinv(H_');
    I_corr=pinv(Sigma2_x_corr);
    
    %% Fussion (Information weighted average)
    I=I_pred+I_corr;
    mu_x_=inv(I)*(I_pred*mu_x_pred_+I_corr*mu_x_corr_);
    Sigma2_x_=inv(I);
    
    sigma_u_2=diag([sigma_theta0^2,Sigma2_x_(2,2),Sigma2_x_(4,4)]);
    
    %%---End--- One step of Kalman filter (k-th)
    
    x_series=[x_series,x_];
    mu_x_series=[mu_x_series, mu_x_];
    z_series=[z_series, z_without_noise];
    z_series_noisy=[z_series_noisy, z_];
    sigma_x_series=[sigma_x_series, sqrt(diag(Sigma2_x_))];
    pred_error_series=[pred_error_series, pred_error];
end

figure
plot(t_series,x_series)

I =legend('$x$','$\theta$','$\dot{x}$','$\dot{\theta}$')
set(I,'interpreter','latex');
I =title('Real state (not known in a real experiment)')
set(I,'interpreter','latex');
saveas(gcf,[fig_dir,'/','trajectory'],'epsc')
saveas(gcf,[fig_dir,'/','trajectory'],'png')

figure
plot(t_series,u_series,'-',t_series,u_series+u_series_noise,'--');
I =legend('$\mathbf{u}=[theta0]$','${meas}(\mathbf{u})=[{meas}(\theta_0)]$')
set(I,'interpreter','latex');
saveas(gcf,[fig_dir,'/','u'],'epsc')
saveas(gcf,[fig_dir,'/','u'],'png')

x_=x_0_
x_series_Euler=[]
for k=1:length(t_series)
    x_series_Euler=[x_series_Euler,x_];
    x_=f(x_, u_series(k), t_series(k),param);
end

figure
plot(t_series,x_series_Euler)
I =legend('$x$','$\theta$','$\dot{x}$','$\dot{\theta}$')
set(I,'interpreter','latex');
I =title('"Real state" as obtained by Euler discretization (not known in a real experiment)')
set(I,'interpreter','latex');
saveas(gcf,[fig_dir,'/','trajectory_Euler'],'epsc')
saveas(gcf,[fig_dir,'/','trajectory_Euler'],'png')

figure
ddx_series=[];
for i=1:length(t_series)
    ddx_series=[ddx_series,ddstate(x_series(:,i),u_series(:,i),du_series(:,i),t_series(1,i),param)];
end

plot(t_series,ddx_series)
I =legend('$\ddot{x}$','$\ddot{\theta}$','$\dot{\ddot{x}}$','$\dot{\ddot{\theta}}$')
set(I,'interpreter','latex');
I =title('Approximation of $\ddot{\mathbf{x}}$ with $\dot{\mathbf{u}}=\mathbf{0}$ to estimate Euler $2^{nd}$ order discretization error')
set(I,'interpreter','latex');
saveas(gcf,[fig_dir,'/','discrete_2nd_x_derivative'],'epsc')
saveas(gcf,[fig_dir,'/','discrete_2nd_x_derivative'],'png')

figure
plot(t_series,z_series,'-',t_series,z_series_noisy,'--')
I =legend('$\dot{\theta}$','$a_x$','$a_y$','${meas}(\dot{\theta})$','${meas}(a_x)$','${meas}(a_y)$')
set(I,'interpreter','latex');
I=title('$\mathbf{z}$ with and without noise')
set(I,'interpreter','latex');
saveas(gcf,[fig_dir,'/','z_without_z_with_noise'],'epsc')
saveas(gcf,[fig_dir,'/','z_without_z_with_noise'],'png')

figure
plot(t_series,z_series_noise,'-')
I =legend('$\dot{\theta}-{meas}(\dot{\theta})$','$a_x-{meas}(a_x)$','$a_y-{meas}(a_y)$')
set(I,'interpreter','latex');
I=title('$\mathbf{z}-{meas}(\mathbf{z})$ with and without noise')
set(I,'interpreter','latex');
saveas(gcf,[fig_dir,'/','z_with_noise_minus_z_without'],'epsc')
saveas(gcf,[fig_dir,'/','z_with_noise_minus_z_without'],'png')

figure
plot(t_series,x_series,'-',t_series,mu_x_series,'--')
xlim([0 T])
I = legend('$x$','$\theta$','$\dot{x}$','$\dot{\theta}$','$\hat{\mu}_{x}$','$\hat{\mu}_\theta$','$\hat{\mu}_{\dot{x}}$','$\hat{\mu}_{\dot{\theta}}$');
set(I,'interpreter','latex');
I=title('$\mathbf{x}$ vs $\hat{\mu}_{\mathbf{x}}$')
set(I,'interpreter','latex');
saveas(gcf,[fig_dir,'/','mu_actual'],'epsc')
saveas(gcf,[fig_dir,'/','mu_actual'],'png')

figure
plot(t_series,x_series-mu_x_series,'-')
xlim([0 T])
I = legend('$x-\hat{\mu}_{x}$','$\theta-\hat{\mu}_\theta$','$\dot{x}-\hat{\mu}_{\dot{x}}$','$\dot{\theta}-\hat{\mu}_{\dot{\theta}}$');
set(I,'interpreter','latex');
I=title('$\hat{\mu}_{\mathbf{x}}-\mathbf{x}$')
set(I,'interpreter','latex');
saveas(gcf,[fig_dir,'/','Error_mu_minus_actual'],'epsc')
saveas(gcf,[fig_dir,'/','Error_mu_minus_actual'],'png')

figure
semilogy(t_series,sigma_x_series,'-')
I =legend('$\sigma_{x}$','$\sigma_{\theta}$','$\sigma_{\dot{x}}$','$\sigma_{\dot{\theta}}$')
set(I,'interpreter','latex');
I=title('$diag({{\Sigma}}_{\mathbf{x}})$')
set(I,'interpreter','latex');
saveas(gcf,[fig_dir,'/','sigma_x'],'epsc')
saveas(gcf,[fig_dir,'/','sigma_x'],'png')

figure
semilogy(t_series,abs(pred_error_series),'-')
I =legend('$\varepsilon_{x}$','$\varepsilon_{\theta}$','$\varepsilon_{\dot{x}}$','$\varepsilon_{\dot{\theta}}$')
set(I,'interpreter','latex');
I=title('Euler method prediction error')
set(I,'interpreter','latex');
saveas(gcf,[fig_dir,'/','varepsilon_x'],'epsc')
saveas(gcf,[fig_dir,'/','varepsilon_x'],'png')

% Observability

%Linear observability near the end of the simulation
OB=obsv(F_,H_)

rank(OB)
size(OB) %Nonlinear observabilty matrix mus be bigger (more rows) than the linear one.

%Nonlinear observability near the end of the simulation
k=k-5

OB=[H(x_series(:,k),u_series(:,k),t_series(:,k),param),
    H(x_series(:,k+1),u_series(:,k+1),t_series(:,k+1),param)*F(x_series(:,k+1),u_series(:,k+1),t_series(:,k+1),param)
    H(x_series(:,k+2),u_series(:,k+2),t_series(:,k+2),param)*F(x_series(:,k+2),u_series(:,k+2),t_series(:,k+2),param)*F(x_series(:,k+1),u_series(:,k+1),t_series(:,k+1),param)
    H(x_series(:,k+3),u_series(:,k+3),t_series(:,k+3),param)*F(x_series(:,k+3),u_series(:,k+3),t_series(:,k+3),param)*F(x_series(:,k+2),u_series(:,k+2),t_series(:,k+2),param)*F(x_series(:,k+1),u_series(:,k+1),t_series(:,k+1),param)
    H(x_series(:,k+4),u_series(:,k+4),t_series(:,k+4),param)*F(x_series(:,k+4),u_series(:,k+4),t_series(:,k+4),param)*F(x_series(:,k+3),u_series(:,k+3),t_series(:,k+3),param)*F(x_series(:,k+2),u_series(:,k+2),t_series(:,k+2),param)*F(x_series(:,k+1),u_series(:,k+1),t_series(:,k+1),param)]

rank(OB)
